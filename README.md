# GorAI LLM Client

A unified LLM client library supporting multiple providers (OpenAI, Anthropic, etc.) with advanced features like tool calling, streaming responses, and automatic conversation loops.

## Version

**Current Version: 0.3.0**

## Features

- ğŸ”Œ **Multiple LLM Providers**: Support for OpenAI and Anthropic APIs
- ğŸ”§ **Tool Calling**: Built-in support for function/tool calling with automatic execution
- ğŸŒŠ **Streaming Responses**: Real-time streaming for better user experience
- ğŸ”„ **Conversation Loops**: Automatic multi-turn conversations with `chatToNextLoop`
- ğŸ’­ **Thinking Support**: Handle model reasoning/thinking content (Anthropic extended thinking)
- ğŸ¯ **Unified Interface**: Consistent API across different providers
- ğŸ› ï¸ **Flexible Tool Execution**: Custom tool executors with `ToolExecutor` interface

## Examples

Check the `examples/` directory for complete examples:
- `chat_with_tools_example.py`: Comprehensive examples of tool calling

## Project Structure

```
GorAI_LLMClient/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py           # create_model factory function
â”‚   â”œâ”€â”€ _model_base.py        # Base model class
â”‚   â”œâ”€â”€ _openai_model.py      # OpenAI implementation
â”‚   â””â”€â”€ _anthropic_model.py   # Anthropic implementation
â”œâ”€â”€ message/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ _message_base.py      # MsgReturn message format
â”œâ”€â”€ executor.py               # Tool executor interfaces
â””â”€â”€ examples/
    â””â”€â”€ chat_with_tools_example.py
```

## License

MIT License