#!/usr/bin/env python3
"""
GorAI_LLMClient - chatToNextLoop ä½¿ç”¨ç¤ºä¾‹
=========================================

æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨ chatToNextLoop æ–¹æ³•å®ç°å¸¦å·¥å…·è°ƒç”¨çš„å¯¹è¯å¾ªç¯ã€‚

åŠŸèƒ½ç‰¹ç‚¹:
1. è‡ªåŠ¨å¤„ç†å¤šè½®å¯¹è¯
2. è‡ªåŠ¨æ£€æµ‹å¹¶æ‰§è¡Œå·¥å…·è°ƒç”¨
3. å°†å·¥å…·ç»“æœåé¦ˆç»™ LLM
4. å¾ªç¯ç›´åˆ° LLM ä¸å†éœ€è¦è°ƒç”¨å·¥å…·

"""

import json
import sys
import os

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥ GorAI_LLMCLient
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from GorAI_LLMCLient import create_model, SimpleFunctionExecutor


# ========================================
# ç¤ºä¾‹ 1: ä½¿ç”¨ SimpleFunctionExecutor
# ========================================

def example_1_simple_executor():
    """ç¤ºä¾‹1ï¼šä½¿ç”¨ç®€å•çš„å‡½æ•°æ‰§è¡Œå™¨"""
    print("=" * 60)
    print("ç¤ºä¾‹ 1: ä½¿ç”¨ SimpleFunctionExecutor")
    print("=" * 60)

    # å®šä¹‰å·¥å…·å‡½æ•°
    def add(a: int, b: int) -> int:
        """åŠ æ³•è®¡ç®—"""
        return a + b

    def multiply(a: int, b: int) -> int:
        """ä¹˜æ³•è®¡ç®—"""
        return a * b

    def get_weather(city: str) -> str:
        """è·å–å¤©æ°”ï¼ˆæ¨¡æ‹Ÿï¼‰"""
        return f"{city}çš„å¤©æ°”ï¼šæ™´å¤©ï¼Œæ¸©åº¦25Â°C"

    # åˆ›å»ºå·¥å…·æ‰§è¡Œå™¨
    executor = SimpleFunctionExecutor({
        "add": add,
        "multiply": multiply,
        "get_weather": get_weather
    })

    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    # æ³¨æ„ï¼šéœ€è¦æ›¿æ¢ä¸ºå®é™…çš„ API é…ç½®
    model = create_model(
        base_url="https://api.openai.com/v1",  # æ›¿æ¢ä¸ºå®é™…çš„ API åœ°å€
        api_key="your-api-key-here",  # æ›¿æ¢ä¸ºå®é™…çš„ API Key
        model_name="gpt-4",
        stream=True,
        router="openai-chat"
    )

    # åˆå§‹åŒ–å·¥å…·
    tools = [
        {
            "name": "add",
            "description": "è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ",
            "parameters": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°"},
                    "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°"}
                },
                "required": ["a", "b"]
            }
        },
        {
            "name": "multiply",
            "description": "è®¡ç®—ä¸¤ä¸ªæ•°çš„ä¹˜ç§¯",
            "parameters": {
                "type": "object",
                "properties": {
                    "a": {"type": "integer", "description": "ç¬¬ä¸€ä¸ªæ•°"},
                    "b": {"type": "integer", "description": "ç¬¬äºŒä¸ªæ•°"}
                },
                "required": ["a", "b"]
            }
        },
        {
            "name": "get_weather",
            "description": "è·å–æŒ‡å®šåŸå¸‚çš„å¤©æ°”",
            "parameters": {
                "type": "object",
                "properties": {
                    "city": {"type": "string", "description": "åŸå¸‚åç§°"}
                },
                "required": ["city"]
            }
        }
    ]

    # è½¬æ¢å·¥å…·æ ¼å¼
    tool_dict = []
    for tool in tools:
        tool_dict.append({
            "name": tool["name"],
            "description": tool["description"],
            "parameters": tool["parameters"],
            "function": None
        })
    model.model_tool_init(tool_dict)

    # å‡†å¤‡æ¶ˆæ¯
    messages = [
        {"role": "user", "content": "è¯·å¸®æˆ‘è®¡ç®— (3 + 5) * 2 çš„ç»“æœ"}
    ]

    # ä½¿ç”¨ chatToNextLoop å¤„ç†å¯¹è¯
    print("\nå¼€å§‹å¯¹è¯...")
    for event in model.chatToNextLoop(messages, executor):
        # è§£æäº‹ä»¶
        event_str = event.decode('utf-8')
        if event_str.startswith('data: '):
            data = json.loads(event_str[6:])

            # æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†
            if data['type'] == 'thinking':
                print(f"[æ€è€ƒ] {data['content']}", end='', flush=True)
            elif data['type'] == 'answer':
                print(f"[å›ç­”] {data['content']}", end='', flush=True)
            elif data['type'] == 'tool_calls':
                print(f"\n[å·¥å…·è°ƒç”¨] {json.dumps(data['tool_calls'], ensure_ascii=False)}")
            elif data['type'] == 'tool_result':
                print(f"[å·¥å…·ç»“æœ] {data['tool_name']}: {data['result']}")
            elif data['type'] == 'error':
                print(f"\n[é”™è¯¯] {data['message']}")
            elif data['type'] == 'end':
                print("\n\n[å¯¹è¯ç»“æŸ]")

    print("\n" + "=" * 60)


# ========================================
# ç¤ºä¾‹ 2: è‡ªå®šä¹‰ ToolExecutor
# ========================================

from GorAI_LLMCLient.executor import ToolExecutor


class CustomToolExecutor(ToolExecutor):
    """è‡ªå®šä¹‰å·¥å…·æ‰§è¡Œå™¨"""

    def __init__(self):
        self.execution_log = []  # æ‰§è¡Œæ—¥å¿—

    def execute_tool(self, tool_name: str, arguments: dict) -> str:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨"""
        # è®°å½•æ‰§è¡Œæ—¥å¿—
        self.execution_log.append({
            "tool": tool_name,
            "args": arguments
        })

        # æ ¹æ®å·¥å…·åç§°æ‰§è¡Œä¸åŒçš„é€»è¾‘
        if tool_name == "search_database":
            query = arguments.get("query", "")
            return f"æ•°æ®åº“æœç´¢ç»“æœï¼šæ‰¾åˆ° {len(query)} æ¡ç›¸å…³è®°å½•"

        elif tool_name == "send_email":
            to = arguments.get("to", "")
            subject = arguments.get("subject", "")
            return f"é‚®ä»¶å·²å‘é€åˆ° {to}ï¼Œä¸»é¢˜ï¼š{subject}"

        else:
            return f"æœªçŸ¥å·¥å…·ï¼š{tool_name}"

    def get_execution_log(self):
        """è·å–æ‰§è¡Œæ—¥å¿—"""
        return self.execution_log


def example_2_custom_executor():
    """ç¤ºä¾‹2ï¼šä½¿ç”¨è‡ªå®šä¹‰æ‰§è¡Œå™¨"""
    print("\n\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: ä½¿ç”¨è‡ªå®šä¹‰ ToolExecutor")
    print("=" * 60)

    # åˆ›å»ºè‡ªå®šä¹‰æ‰§è¡Œå™¨
    executor = CustomToolExecutor()

    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆé…ç½®åŒä¸Šï¼‰
    model = create_model(
        base_url="https://api.openai.com/v1",
        api_key="your-api-key-here",
        model_name="gpt-4",
        stream=True,
        router="openai-chat"
    )

    # åˆå§‹åŒ–å·¥å…·
    tools = [
        {
            "name": "search_database",
            "description": "æœç´¢æ•°æ®åº“",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {"type": "string", "description": "æœç´¢å…³é”®è¯"}
                },
                "required": ["query"]
            }
        },
        {
            "name": "send_email",
            "description": "å‘é€é‚®ä»¶",
            "parameters": {
                "type": "object",
                "properties": {
                    "to": {"type": "string", "description": "æ”¶ä»¶äºº"},
                    "subject": {"type": "string", "description": "é‚®ä»¶ä¸»é¢˜"}
                },
                "required": ["to", "subject"]
            }
        }
    ]

    tool_dict = []
    for tool in tools:
        tool_dict.append({
            "name": tool["name"],
            "description": tool["description"],
            "parameters": tool["parameters"],
            "function": None
        })
    model.model_tool_init(tool_dict)

    # å‡†å¤‡æ¶ˆæ¯
    messages = [
        {"role": "user", "content": "æœç´¢æ•°æ®åº“ä¸­å…³äº'äººå·¥æ™ºèƒ½'çš„å†…å®¹ï¼Œå¹¶å‘é€é‚®ä»¶ç»™ admin@example.com"}
    ]

    # ä½¿ç”¨ chatToNextLoop å¤„ç†å¯¹è¯
    print("\nå¼€å§‹å¯¹è¯...")
    for event in model.chatToNextLoop(messages, executor):
        # å¤„ç†äº‹ä»¶ï¼ˆåŒç¤ºä¾‹1ï¼‰
        event_str = event.decode('utf-8')
        if event_str.startswith('data: '):
            data = json.loads(event_str[6:])

            if data['type'] == 'thinking':
                print(f"[æ€è€ƒ] {data['content']}", end='', flush=True)
            elif data['type'] == 'answer':
                print(f"[å›ç­”] {data['content']}", end='', flush=True)
            elif data['type'] == 'tool_calls':
                print(f"\n[å·¥å…·è°ƒç”¨] {json.dumps(data['tool_calls'], ensure_ascii=False)}")
            elif data['type'] == 'tool_result':
                print(f"[å·¥å…·ç»“æœ] {data['tool_name']}: {data['result']}")
            elif data['type'] == 'end':
                print("\n\n[å¯¹è¯ç»“æŸ]")

    # æ‰“å°æ‰§è¡Œæ—¥å¿—
    print("\næ‰§è¡Œæ—¥å¿—:")
    for log in executor.get_execution_log():
        print(f"  - {log['tool']}: {log['args']}")

    print("\n" + "=" * 60)


# ========================================
# ç¤ºä¾‹ 3: æ”¯æŒä¸­æ–­çš„å¯¹è¯
# ========================================

def example_3_interruptible_chat():
    """ç¤ºä¾‹3ï¼šæ”¯æŒä¸­æ–­çš„å¯¹è¯"""
    print("\n\n" + "=" * 60)
    print("ç¤ºä¾‹ 3: æ”¯æŒä¸­æ–­çš„å¯¹è¯")
    print("=" * 60)

    # åˆ›å»ºæ‰§è¡Œå™¨
    executor = SimpleFunctionExecutor({
        "add": lambda a, b: a + b
    })

    # åˆ›å»ºæ¨¡å‹
    model = create_model(
        base_url="https://api.openai.com/v1",
        api_key="your-api-key-here",
        model_name="gpt-4",
        stream=True,
        router="openai-chat"
    )

    # åˆå§‹åŒ–å·¥å…·
    tool_dict = [{
        "name": "add",
        "description": "åŠ æ³•",
        "parameters": {
            "type": "object",
            "properties": {
                "a": {"type": "integer"},
                "b": {"type": "integer"}
            }
        },
        "function": None
    }]
    model.model_tool_init(tool_dict)

    # ä¸­æ–­æ ‡å¿—
    should_interrupt = False

    def interrupt_check():
        """ä¸­æ–­æ£€æŸ¥å‡½æ•°"""
        return should_interrupt

    messages = [{"role": "user", "content": "è®¡ç®—1+2"}]

    print("\nå¼€å§‹å¯¹è¯ï¼ˆå¯ä¸­æ–­ï¼‰...")

    # æ¨¡æ‹Ÿï¼šå¤„ç†å‡ ä¸ªäº‹ä»¶åä¸­æ–­
    event_count = 0
    for event in model.chatToNextLoop(messages, executor, interrupt_check=interrupt_check):
        event_count += 1

        # æ¨¡æ‹Ÿï¼šå¤„ç†5ä¸ªäº‹ä»¶åä¸­æ–­
        if event_count > 5:
            print("\n[è§¦å‘ä¸­æ–­]")
            should_interrupt = True

        event_str = event.decode('utf-8')
        if event_str.startswith('data: '):
            data = json.loads(event_str[6:])

            if data['type'] == 'answer':
                print(f"[å›ç­”] {data['content']}", end='', flush=True)
            elif data['type'] == 'interrupted':
                print(f"\n[å·²ä¸­æ–­] {data['message']}")
                break
            elif data['type'] == 'end':
                print("\n[å¯¹è¯ç»“æŸ]")

    print("\n" + "=" * 60)


# ========================================
# ä¸»å‡½æ•°
# ========================================

if __name__ == "__main__":
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘      GorAI_LLMClient chatToNextLoop ä½¿ç”¨ç¤ºä¾‹            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

æ³¨æ„ï¼šè¿è¡Œæ­¤ç¤ºä¾‹å‰ï¼Œè¯·å…ˆé…ç½®æ­£ç¡®çš„ API åœ°å€å’Œå¯†é’¥ï¼

æœ¬ç¤ºä¾‹åŒ…å«:
1. ä½¿ç”¨ SimpleFunctionExecutor çš„åŸºç¡€ç¤ºä¾‹
2. ä½¿ç”¨è‡ªå®šä¹‰ ToolExecutor çš„é«˜çº§ç¤ºä¾‹
3. æ”¯æŒä¸­æ–­çš„å¯¹è¯ç¤ºä¾‹

""")

    # æç¤ºç”¨æˆ·
    print("âš ï¸  è­¦å‘Šï¼šæ­¤ç¤ºä¾‹éœ€è¦æœ‰æ•ˆçš„ API é…ç½®æ‰èƒ½è¿è¡Œï¼")
    print("âš ï¸  è¯·ä¿®æ”¹ä»£ç ä¸­çš„ base_url å’Œ api_key åå†è¿è¡Œã€‚")
    print("\nå¦‚æœå·²é…ç½®ï¼ŒæŒ‰å›è½¦ç»§ç»­...")
    input()

    # è¿è¡Œç¤ºä¾‹ï¼ˆå–æ¶ˆæ³¨é‡Šä»¥è¿è¡Œï¼‰
    # example_1_simple_executor()
    # example_2_custom_executor()
    # example_3_interruptible_chat()

    print("\nâœ… ç¤ºä¾‹ä»£ç è¯´æ˜å®Œæ¯•ï¼")
    print("ğŸ’¡ è¯·å–æ¶ˆæ³¨é‡Šç›¸åº”çš„ç¤ºä¾‹å‡½æ•°æ¥è¿è¡Œã€‚")
